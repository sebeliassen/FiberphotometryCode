{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Gq-DREADD_CPT_Training_Stages/Stage1/Post'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_and_prepare_sessions\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MiceAnalysis\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/project_root/notebooks/sam/../../main.py:53\u001b[0m\n\u001b[1;32m     50\u001b[0m     assign_sessions_signal_info(sessions)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sessions\n\u001b[0;32m---> 53\u001b[0m sessions \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_prepare_sessions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Gq-DREADD_CPT_Training_Stages/Stage1/Post\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_from_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_bad_signal_sessions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# save sessions to pickle\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Gq-DREADD_CPT_Training_Stages/sessions_stage1_post.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/project_root/notebooks/sam/../../main.py:35\u001b[0m, in \u001b[0;36mload_and_prepare_sessions\u001b[0;34m(baseline_dir, first_n_dirs, load_from_pickle, remove_bad_signal_sessions)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sessions\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# load in sessions\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m sessions \u001b[38;5;241m=\u001b[39m \u001b[43mload_all_sessions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_n_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_bad_signal_sessions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_bad_signal_sessions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# rename columns of dfs\u001b[39;00m\n\u001b[1;32m     38\u001b[0m Renamer\u001b[38;5;241m.\u001b[39mrename_sessions_data(sessions, RENAME_PATTERNS)\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/project_root/notebooks/sam/../../data/data_loading.py:144\u001b[0m, in \u001b[0;36mload_all_sessions\u001b[0;34m(baseline_dir, first_n_dirs, remove_bad_signal_sessions)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_all_sessions\u001b[39m(baseline_dir, first_n_dirs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, remove_bad_signal_sessions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# Get a list of all subdirectories within the baseline directory\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(baseline_dir, d))]\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Sort the subdirectories based on the trial number\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     sorted_subdirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(subdirs, key\u001b[38;5;241m=\u001b[39msort_key_func)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Gq-DREADD_CPT_Training_Stages/Stage1/Post'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from main import load_and_prepare_sessions\n",
    "from processing.session_sampling import MiceAnalysis\n",
    "import config\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sessions = load_and_prepare_sessions(\"../../../Baseline\", load_from_pickle=True, remove_bad_signal_sessions=True)\n",
    "mouse_analyser = MiceAnalysis(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_wise_idxs(raw_df, actions_attr_dict):\n",
    "    # Define events of interest including 'Display Image'\n",
    "    events_of_interest = list(actions_attr_dict.keys())\n",
    "\n",
    "    # Get raw data and filter for events of interest\n",
    "    item_df = raw_df[[\"Item_Name\"]]\n",
    "    filtered_df = item_df[item_df[\"Item_Name\"].isin(events_of_interest)].reset_index()\n",
    "\n",
    "    # Initialize defaultdict to store the pairs\n",
    "    event_pairs_dict = defaultdict(list)\n",
    "\n",
    "    # Iterate through the filtered_df row by row\n",
    "    for i in range(len(filtered_df) - 1):\n",
    "        current_event = filtered_df.at[i, \"Item_Name\"]\n",
    "        next_event = filtered_df.at[i + 1, \"Item_Name\"]\n",
    "        if current_event in events_of_interest and next_event in events_of_interest:\n",
    "            event_pairs_dict[(current_event, next_event)]\\\n",
    "                .append((filtered_df.at[i, \"index\"], filtered_df.at[i + 1, \"index\"]))\n",
    "\n",
    "    return event_pairs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_pair_signals(session, brain_region):\n",
    "    signal_order = []\n",
    "    all_session_signals = []\n",
    "\n",
    "    for event in (['hit', 'miss', 'mistake', 'cor_reject']):\n",
    "        curr_signal_info = session.signal_info.get((brain_region, event))\n",
    "        if curr_signal_info is None:\n",
    "            continue\n",
    "        curr_ranges = curr_signal_info['signal_idx_ranges']\n",
    "\n",
    "        len_before = sum(len(arr) for arr in all_session_signals)\n",
    "        all_session_signals.append(curr_signal_info['signal_matrix'])\n",
    "        len_after = sum(len(arr) for arr in all_session_signals)\n",
    "\n",
    "        event_list = [event] * len(curr_ranges)\n",
    "        idx_list = range(len_before, len_after)\n",
    "        signal_order.extend(zip(curr_ranges, event_list, idx_list))\n",
    "\n",
    "    _, events, matrix_idx = zip(*sorted(signal_order, key=lambda x: x[0][0]))\n",
    "    signal_matrix = np.vstack(all_session_signals)[matrix_idx, :]\n",
    "\n",
    "    pair_dict = defaultdict(list)\n",
    "\n",
    "    for i in range(len(events) - 1):\n",
    "        curr_event = events[i]\n",
    "        next_event = events[i + 1]\n",
    "        #if next_event == 'hit':\n",
    "        pair_dict[(curr_event, next_event, brain_region)].append(signal_matrix[i+1])\n",
    "\n",
    "    for k, v in pair_dict.items():\n",
    "        pair_dict[k] = np.vstack(v)\n",
    "\n",
    "    return pair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_dict = defaultdict(list)\n",
    "\n",
    "for session in sessions:\n",
    "    for brain_region in config.all_brain_regions:\n",
    "        for event in (['hit', 'miss', 'mistake', 'cor_reject']):\n",
    "            if session.signal_info.get((brain_region, event)) is None:\n",
    "                    continue\n",
    "\n",
    "            pair_dict_part = get_session_pair_signals(session, brain_region)\n",
    "            if pair_dict_part is None:\n",
    "                continue\n",
    "            for k, v in pair_dict_part.items():\n",
    "                pair_dict[k].append(v)\n",
    "\n",
    "for k, v in pair_dict.items():\n",
    "    pair_dict[k] = np.vstack(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('miss', 'cor_reject', 'DMS') 3320\n",
      "('cor_reject', 'miss', 'DMS') 3524\n",
      "('cor_reject', 'hit', 'DMS') 2350\n",
      "('hit', 'cor_reject', 'DMS') 2147\n",
      "('cor_reject', 'cor_reject', 'DMS') 9445\n",
      "('cor_reject', 'mistake', 'DMS') 952\n",
      "('mistake', 'cor_reject', 'DMS') 1348\n",
      "('hit', 'miss', 'DMS') 505\n",
      "('miss', 'miss', 'DMS') 978\n",
      "('miss', 'hit', 'DMS') 438\n",
      "('miss', 'mistake', 'DMS') 280\n",
      "('hit', 'hit', 'DMS') 372\n",
      "('hit', 'mistake', 'DMS') 120\n",
      "('miss', 'cor_reject', 'DLS') 3456\n",
      "('cor_reject', 'miss', 'DLS') 3672\n",
      "('cor_reject', 'hit', 'DLS') 1764\n",
      "('hit', 'cor_reject', 'DLS') 1628\n",
      "('cor_reject', 'cor_reject', 'DLS') 9112\n",
      "('cor_reject', 'mistake', 'DLS') 632\n",
      "('mistake', 'cor_reject', 'DLS') 984\n",
      "('hit', 'miss', 'DLS') 460\n",
      "('miss', 'miss', 'DLS') 1048\n",
      "('miss', 'hit', 'DLS') 424\n",
      "('miss', 'mistake', 'DLS') 272\n",
      "('hit', 'hit', 'DLS') 204\n",
      "('hit', 'mistake', 'DLS') 80\n",
      "('mistake', 'mistake', 'DLS') 268\n",
      "('mistake', 'mistake', 'DMS') 364\n",
      "('miss', 'cor_reject', 'VS') 2786\n",
      "('cor_reject', 'miss', 'VS') 2917\n",
      "('cor_reject', 'cor_reject', 'VS') 7950\n",
      "('miss', 'miss', 'VS') 671\n",
      "('cor_reject', 'hit', 'VS') 2279\n",
      "('hit', 'cor_reject', 'VS') 2030\n",
      "('miss', 'hit', 'VS') 395\n",
      "('miss', 'mistake', 'VS') 284\n",
      "('mistake', 'cor_reject', 'VS') 1372\n",
      "('cor_reject', 'mistake', 'VS') 1004\n",
      "('mistake', 'mistake', 'VS') 532\n",
      "('hit', 'miss', 'VS') 532\n",
      "('hit', 'hit', 'VS') 308\n",
      "('hit', 'mistake', 'VS') 88\n"
     ]
    }
   ],
   "source": [
    "for k, v in pair_dict.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_reg_to_color = {'VS': 'purple',\n",
    "                      'DMS': 'forestgreen',\n",
    "                      'DLS': 'C0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_plot_signals(pair_dict, event_type, brain_region, smoothing_len=10):\n",
    "    # Assuming all_signals is predefined\n",
    "    event1, event2 = event_type\n",
    "    signals = pair_dict[event1, event2, brain_region]\n",
    "\n",
    "    interval_start = config.peak_interval_config[\"interval_start\"]\n",
    "    interval_end = config.peak_interval_config[\"interval_end\"]\n",
    "    fps = config.PLOTTING_CONFIG['fps']\n",
    "    \n",
    "    xs = np.arange(-interval_start, interval_end) / fps\n",
    "    \n",
    "    # Smooth the mean signal\n",
    "    ys = np.mean(signals, axis=0)\n",
    "    window = np.ones(smoothing_len) / smoothing_len\n",
    "    ys = np.convolve(ys, window, 'same')\n",
    "\n",
    "    # Calculate the standard deviation of the mean\n",
    "    std_signal = np.std(signals, axis=0) / np.sqrt(len(signals))\n",
    "\n",
    "    # Use scipy.stats.norm.interval to get the 95% confidence interval\n",
    "    alpha = 0.95\n",
    "    ci_lower, ci_upper = stats.norm.interval(alpha, loc=ys, scale=std_signal)\n",
    "\n",
    "    # The lower and upper bounds\n",
    "    lb = ci_lower.min()\n",
    "    ub = ci_upper.max()\n",
    "\n",
    "    ylim = (lb, ub)\n",
    "    \n",
    "    # Assuming brain_reg_to_color is predefined\n",
    "    color = brain_reg_to_color[brain_region]\n",
    "\n",
    "    plt.figure(dpi=300)\n",
    "    plt.plot(xs[100: -100], ys[100: -100], color=color, label='Mean Signal')\n",
    "    plt.fill_between(xs[100: -100], ci_lower[100: -100], ci_upper[100: -100], color=color, alpha=0.2, label='95% CI')\n",
    "    plt.ylim(ylim)\n",
    "    plt.title(f'{event_type}, {brain_region}, (n = {len(signals)})')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('z-score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'{event1}_to_{event2}_{brain_region}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('miss', 'cor_reject', 'DMS'), ('cor_reject', 'miss', 'DMS'), ('cor_reject', 'hit', 'DMS'), ('hit', 'cor_reject', 'DMS'), ('cor_reject', 'cor_reject', 'DMS'), ('cor_reject', 'mistake', 'DMS'), ('mistake', 'cor_reject', 'DMS'), ('hit', 'miss', 'DMS'), ('miss', 'miss', 'DMS'), ('miss', 'hit', 'DMS'), ('miss', 'mistake', 'DMS'), ('hit', 'hit', 'DMS'), ('hit', 'mistake', 'DMS'), ('miss', 'cor_reject', 'DLS'), ('cor_reject', 'miss', 'DLS'), ('cor_reject', 'hit', 'DLS'), ('hit', 'cor_reject', 'DLS'), ('cor_reject', 'cor_reject', 'DLS'), ('cor_reject', 'mistake', 'DLS'), ('mistake', 'cor_reject', 'DLS'), ('hit', 'miss', 'DLS'), ('miss', 'miss', 'DLS'), ('miss', 'hit', 'DLS'), ('miss', 'mistake', 'DLS'), ('hit', 'hit', 'DLS'), ('hit', 'mistake', 'DLS'), ('mistake', 'mistake', 'DLS'), ('mistake', 'mistake', 'DMS'), ('miss', 'cor_reject', 'VS'), ('cor_reject', 'miss', 'VS'), ('cor_reject', 'cor_reject', 'VS'), ('miss', 'miss', 'VS'), ('cor_reject', 'hit', 'VS'), ('hit', 'cor_reject', 'VS'), ('miss', 'hit', 'VS'), ('miss', 'mistake', 'VS'), ('mistake', 'cor_reject', 'VS'), ('cor_reject', 'mistake', 'VS'), ('mistake', 'mistake', 'VS'), ('hit', 'miss', 'VS'), ('hit', 'hit', 'VS'), ('hit', 'mistake', 'VS')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('miss', 'cor_reject', 'DMS'), ('cor_reject', 'miss', 'DMS'), ('cor_reject', 'hit', 'DMS'), ('hit', 'cor_reject', 'DMS'), ('cor_reject', 'cor_reject', 'DMS'), ('cor_reject', 'mistake', 'DMS'), ('mistake', 'cor_reject', 'DMS'), ('hit', 'miss', 'DMS'), ('miss', 'miss', 'DMS'), ('miss', 'hit', 'DMS'), ('miss', 'mistake', 'DMS'), ('hit', 'hit', 'DMS'), ('hit', 'mistake', 'DMS'), ('miss', 'cor_reject', 'DLS'), ('cor_reject', 'miss', 'DLS'), ('cor_reject', 'hit', 'DLS'), ('hit', 'cor_reject', 'DLS'), ('cor_reject', 'cor_reject', 'DLS'), ('cor_reject', 'mistake', 'DLS'), ('mistake', 'cor_reject', 'DLS'), ('hit', 'miss', 'DLS'), ('miss', 'miss', 'DLS'), ('miss', 'hit', 'DLS'), ('miss', 'mistake', 'DLS'), ('hit', 'hit', 'DLS'), ('hit', 'mistake', 'DLS'), ('mistake', 'mistake', 'DLS'), ('mistake', 'mistake', 'DMS'), ('miss', 'cor_reject', 'VS'), ('cor_reject', 'miss', 'VS'), ('cor_reject', 'cor_reject', 'VS'), ('miss', 'miss', 'VS'), ('cor_reject', 'hit', 'VS'), ('hit', 'cor_reject', 'VS'), ('miss', 'hit', 'VS'), ('miss', 'mistake', 'VS'), ('mistake', 'cor_reject', 'VS'), ('cor_reject', 'mistake', 'VS'), ('mistake', 'mistake', 'VS'), ('hit', 'miss', 'VS'), ('hit', 'hit', 'VS'), ('hit', 'mistake', 'VS')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(pair_dict.keys(), key=lambda x: x[-2]):\n",
    "    event1, event2, br = k\n",
    "    event = (event1, event2)\n",
    "    preprocess_and_plot_signals(pair_dict, event, br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sund",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
