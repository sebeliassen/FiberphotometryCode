{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from main import load_and_prepare_sessions\n",
    "from processing.session_sampling import MiceAnalysis\n",
    "from analysis.timepoint_analysis import sample_signals_and_metrics, sample_low_and_high_signals\n",
    "from config import all_brain_regions, all_event_types, all_metrics\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from utils import mouse_br_events_count\n",
    "\n",
    "window_size = 5\n",
    "window = np.ones(window_size) / window_size\n",
    "\n",
    "sessions = load_and_prepare_sessions(\"../../../Baseline\", load_from_pickle=True, remove_bad_signal_sessions=True)\n",
    "mouse_analyser = MiceAnalysis(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all aggregated signals\n",
    "all_event_signals = []\n",
    "labels = []\n",
    "\n",
    "for mouse in mouse_analyser.mice_dict.values():\n",
    "    mouse_sessions = mouse.sessions\n",
    "    for brain_region, event in product(all_brain_regions, ['hit', 'mistake', 'miss', 'cor_reject', 'reward_collect']):\n",
    "        mouse_signals = [] \n",
    "        for session in mouse_sessions:\n",
    "            if session.signal_info.get((brain_region, event)) is None:\n",
    "                continue\n",
    "            signals = sample_signals_and_metrics([session], event, brain_region)[0]\n",
    "            mouse_signals.append(signals[:, 150:250])\n",
    "        if len(mouse_signals) == 0:\n",
    "            continue\n",
    "        mouse_signals = np.vstack(mouse_signals)\n",
    "        sample_idxs = np.random.choice(len(mouse_signals), 100, replace=True)\n",
    "        all_event_signals.append(mouse_signals)\n",
    "        labels.extend([(mouse.mouse_id, brain_region, event)] * len(mouse_signals))\n",
    "\n",
    "all_event_signals = np.vstack(all_event_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20690"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20690"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_event_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the data to a pickle file\n",
    "with open('all_event_signals.pkl', 'wb') as f:\n",
    "    pickle.dump(all_event_signals, f)\n",
    "\n",
    "# Save the data to a pickle file\n",
    "with open('labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_labels, br_labels, event_labels = zip(*labels)\n",
    "mouse_labels = np.array(mouse_labels)\n",
    "br_labels = np.array(br_labels)\n",
    "event_labels = np.array(event_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the br_labels and event_labels to numerical values\n",
    "br_label_encoder = LabelEncoder()\n",
    "br_labels_encoded = br_label_encoder.fit_transform(br_labels)\n",
    "\n",
    "event_label_encoder = LabelEncoder()\n",
    "event_labels_encoded = event_label_encoder.fit_transform(event_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mouse_labels = np.unique(mouse_labels)\n",
    "train_mice, test_mice = train_test_split(unique_mouse_labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.isin(mouse_labels, train_mice)\n",
    "test_mask = np.isin(mouse_labels, test_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event_signals_train = all_event_signals[train_mask]\n",
    "all_event_signals_test = all_event_signals[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_labels_train = br_labels_encoded[train_mask]\n",
    "br_labels_test = br_labels_encoded[test_mask]\n",
    "\n",
    "event_labels_train = event_labels_encoded[train_mask]\n",
    "event_labels_test = event_labels_encoded[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes after adjustment:\")\n",
    "print(f\"all_event_signals_train shape: {all_event_signals_train.shape}\")\n",
    "print(f\"br_labels_train shape: {br_labels_train.shape}\")\n",
    "print(f\"event_labels_train shape: {event_labels_train.shape}\")\n",
    "print(f\"all_event_signals_test shape: {all_event_signals_test.shape}\")\n",
    "print(f\"br_labels_test shape: {br_labels_test.shape}\")\n",
    "print(f\"event_labels_test shape: {event_labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming all_event_signals_train, br_labels_train, event_labels_train, \n",
    "# all_event_signals_test, br_labels_test, event_labels_test are already defined\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "all_event_signals_train = torch.tensor(all_event_signals_train, dtype=torch.float32)\n",
    "br_labels_train = torch.tensor(br_labels_train, dtype=torch.long)\n",
    "event_labels_train = torch.tensor(event_labels_train, dtype=torch.long)\n",
    "\n",
    "all_event_signals_test = torch.tensor(all_event_signals_test, dtype=torch.float32)\n",
    "br_labels_test = torch.tensor(br_labels_test, dtype=torch.long)\n",
    "event_labels_test = torch.tensor(event_labels_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(all_event_signals_train, br_labels_train, event_labels_train)\n",
    "test_dataset = TensorDataset(all_event_signals_test, br_labels_test, event_labels_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, br_output_size, event_output_size, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc_br = nn.Linear(hidden_size, br_output_size)\n",
    "        self.fc_event = nn.Linear(hidden_size, event_output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step for both br and event labels\n",
    "        br_out = self.fc_br(out[:, -1, :])\n",
    "        event_out = self.fc_event(out[:, -1, :])\n",
    "        return br_out, event_out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 1  # One feature per time step\n",
    "hidden_size = 128\n",
    "br_output_size = len(torch.unique(br_labels_train))  # Number of unique br_labels\n",
    "event_output_size = len(torch.unique(event_labels_train))  # Number of unique event_labels\n",
    "num_layers = 2  # Two-layer LSTM\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, br_output_size, event_output_size, num_layers)\n",
    "criterion_br = nn.CrossEntropyLoss()\n",
    "criterion_event = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)  # Move model to the configured device\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_br_correct = 0\n",
    "    train_event_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for signals, br_labels, event_labels in train_loader:\n",
    "        # Move tensors to the configured device\n",
    "        signals = signals.to(device).unsqueeze(-1)\n",
    "        br_labels = br_labels.to(device)\n",
    "        event_labels = event_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        br_outputs, event_outputs = model(signals)\n",
    "        br_loss = criterion_br(br_outputs, br_labels)\n",
    "        event_loss = criterion_event(event_outputs, event_labels)\n",
    "        loss = br_loss\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, br_predicted = torch.max(br_outputs.data, 1)\n",
    "        _, event_predicted = torch.max(event_outputs.data, 1)\n",
    "        \n",
    "        train_total += br_labels.size(0)\n",
    "        train_br_correct += (br_predicted == br_labels).sum().item()\n",
    "        train_event_correct += (event_predicted == event_labels).sum().item()\n",
    "\n",
    "    train_br_accuracy = 100 * train_br_correct / train_total\n",
    "    train_event_accuracy = 100 * train_event_correct / train_total\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    br_correct = 0\n",
    "    event_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, br_labels, event_labels in test_loader:\n",
    "            signals = signals.to(device).unsqueeze(-1)\n",
    "            br_labels = br_labels.to(device)\n",
    "            event_labels = event_labels.to(device)\n",
    "            \n",
    "            br_outputs, event_outputs = model(signals)\n",
    "            _, br_predicted = torch.max(br_outputs.data, 1)\n",
    "            _, event_predicted = torch.max(event_outputs.data, 1)\n",
    "            \n",
    "            total += br_labels.size(0)\n",
    "            br_correct += (br_predicted == br_labels).sum().item()\n",
    "            event_correct += (event_predicted == event_labels).sum().item()\n",
    "    \n",
    "    br_accuracy = 100 * br_correct / total\n",
    "    event_accuracy = 100 * event_correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'Train Accuracy for br_labels: {train_br_accuracy:.2f}%, '\n",
    "          f'Train Accuracy for event_labels: {train_event_accuracy:.2f}%, '\n",
    "          f'Test Accuracy for br_labels: {br_accuracy:.2f}%, '\n",
    "          f'Test Accuracy for event_labels: {event_accuracy:.2f}%')\n",
    "\n",
    "# Final evaluation on the test set after training\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    br_correct = 0\n",
    "    event_correct = 0\n",
    "    total = 0\n",
    "    for signals, br_labels, event_labels in test_loader:\n",
    "        signals = signals.to(device).unsqueeze(-1)\n",
    "        br_labels = br_labels.to(device)\n",
    "        event_labels = event_labels.to(device)\n",
    "        \n",
    "        br_outputs, event_outputs = model(signals)\n",
    "        _, br_predicted = torch.max(br_outputs.data, 1)\n",
    "        _, event_predicted = torch.max(event_outputs.data, 1)\n",
    "        \n",
    "        total += br_labels.size(0)\n",
    "        br_correct += (br_predicted == br_labels).sum().item()\n",
    "        event_correct += (event_predicted == event_labels).sum().item()\n",
    "    \n",
    "    print(f'Final Test Accuracy for br_labels: {100 * br_correct / total:.2f}%')\n",
    "    print(f'Final Test Accuracy for event_labels: {100 * event_correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUND",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
