{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import warnings\n",
    "import pytest\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from fiberphotometry.config import PLOTTING_CONFIG\n",
    "from fiberphotometry.data.data_loading import DataContainer, load_all_sessions\n",
    "from fiberphotometry.data.session_loading import populate_containers\n",
    "from fiberphotometry.data.syncer import sync_session\n",
    "from fiberphotometry.data.timepoint_processing import create_event_idxs_container_for_sessions\n",
    "from fiberphotometry.processing.plotting_setup import PlottingSetup\n",
    "from fiberphotometry.processing.signal_info_setup import assign_sessions_signal_info\n",
    "\n",
    "# adjust to your project layout\n",
    "SRC = Path(\"/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/trial_Gq-DREADD_CPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = load_all_sessions(\n",
    "            baseline_dir=str(SRC),\n",
    "            session_type=\"cpt\",\n",
    "            remove_bad_signal_sessions=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_containers(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    sync_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions_attr_dict_for():\n",
    "    return {\n",
    "            \"Hit\":      \"hit\",\n",
    "            \"Mistake\":  \"mistake\",\n",
    "            \"Missed Hit\":\"miss\",\n",
    "            \"Correction Trial Correct Rejection\":\"cor_reject\",\n",
    "            \"Correct Rejection\":\"cor_reject\"\n",
    "        }\n",
    "\n",
    "def reward_attr_dict_for():\n",
    "    return {\"Reward Collected Start ITI\":\"reward_collect\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_event_idxs_container_for_sessions(\n",
    "    sessions,\n",
    "    actions_attr_dict_for(),\n",
    "    reward_attr_dict_for())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Plotting setup\n",
    "PlottingSetup(**PLOTTING_CONFIG['cpt']) \\\n",
    "    .apply_plotting_setup_to_sessions(sessions)\n",
    "\n",
    "# 4) Signal‚Äêinfo\n",
    "assign_sessions_signal_info(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_genotypes(sessions, mice_gen_dict):\n",
    "    \"\"\"\n",
    "    Updates the genotypes for a list of sessions based on the provided genotype mapping.\n",
    "    Prints whether the genotypes are valid ('TH-Cre', 'Wildtype') \n",
    "    and the number of genotype changes made.\n",
    "\n",
    "    Parameters:\n",
    "    - sessions: A list of session objects to process.\n",
    "    - mice_gen_dict: A dictionary mapping mouse IDs to new genotypes.\n",
    "    \"\"\"\n",
    "    geno_mapping = {\n",
    "        \"Cre\": \"TH-Cre\",\n",
    "        \"WT\": \"Wildtype\"\n",
    "    }\n",
    "    # Map mice_gen_dict to use TH-Cre and Wildtype\n",
    "    mapped_genotypes = {k: geno_mapping[v] for k, v in mice_gen_dict.items()}\n",
    "    \n",
    "    # Initialize counters and trackers\n",
    "    valid_genotypes = {'TH-Cre', 'Wildtype'}\n",
    "    all_genotypes = set()\n",
    "    genotype_changes = 0\n",
    "\n",
    "    for session in sessions:\n",
    "        original_genotype = session.genotype\n",
    "        int_id = int(session.mouse_id)\n",
    "        \n",
    "        if int_id in mapped_genotypes:\n",
    "            session.genotype = mapped_genotypes[int_id]\n",
    "            # Count changes if the genotype was updated\n",
    "            if session.genotype != original_genotype:\n",
    "                genotype_changes += 1\n",
    "        \n",
    "        all_genotypes.add(session.genotype)\n",
    "    \n",
    "    # Print results\n",
    "    if all_genotypes.issubset(valid_genotypes):\n",
    "        print(f\"Valid genotypes found: {all_genotypes}\")\n",
    "    else:\n",
    "        print(f\"Invalid genotypes found: {all_genotypes}\")\n",
    "    \n",
    "    print(f\"Genotype changes made: {genotype_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_gen_dict = {\n",
    "    69: \"Cre\",\n",
    "    71: \"WT\",\n",
    "    73: \"Cre\",\n",
    "    75: \"WT\",\n",
    "    77: \"Cre\",\n",
    "    79: \"WT\",\n",
    "    85: \"WT\",\n",
    "    87: \"WT\",\n",
    "    135: \"WT\",\n",
    "    137: \"WT\",\n",
    "    139: \"Cre\",\n",
    "    133: \"WT\",\n",
    "    127: \"WT\",\n",
    "    125: \"WT\",\n",
    "    129: \"Cre\",\n",
    "    131: \"WT\",\n",
    "    143: \"Cre\",\n",
    "    145: \"WT\",\n",
    "    147: \"WT\",\n",
    "    157: \"Cre\",\n",
    "    159: \"Cre\",\n",
    "    161: \"WT\",\n",
    "    171: \"Cre\",\n",
    "    173: \"Cre\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_genotypes(sessions, mice_gen_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiberphotometry.analysis import performance_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_performance_all(session, window_time, tau=100):\n",
    "    \"\"\"\n",
    "    Computes running performance metrics over a sliding window,\n",
    "    using exponentially weighted event counts so that newer events\n",
    "    influence the metric more than older ones.\n",
    "\n",
    "    Parameters:\n",
    "    - session: The session object containing event data.\n",
    "    - window_time: The window duration (in seconds) over which to compute metrics.\n",
    "    - tau: Time constant (in seconds) for exponential decay. Smaller tau gives faster decay.\n",
    "\n",
    "    Returns:\n",
    "    - event_times: Numpy array of event times within the analysis window.\n",
    "    - metrics: A dictionary where keys are metric names and values are lists of\n",
    "               the computed performance values at each event.\n",
    "    \"\"\"\n",
    "    # Filter out unwanted events\n",
    "    raw_df = session.dfs.data['raw']\n",
    "    filtered_df = raw_df.loc[session.events_of_interest_df[\"index\"]]\n",
    "    filtered_df = filtered_df[~filtered_df['Item_Name'].isin(['Display Image'])]\n",
    "    \n",
    "    event_times = filtered_df['sec_from_zero'].values\n",
    "    event_names = filtered_df['Item_Name'].values\n",
    "    \n",
    "    # Define analysis window: from blank image to 30 minutes later\n",
    "    blank_image_time = raw_df.iloc[session.cpt]['sec_from_zero']\n",
    "    start_time = blank_image_time\n",
    "    end_time = blank_image_time + 30 * 60  # 30 minutes\n",
    "    \n",
    "    start_idx = np.searchsorted(event_times, start_time, side='left')\n",
    "    end_idx = np.searchsorted(event_times, end_time, side='right')\n",
    "    \n",
    "    event_times = event_times[start_idx:end_idx]\n",
    "    event_names = event_names[start_idx:end_idx]\n",
    "    \n",
    "    # Combine times and names into a list of events.\n",
    "    events = list(zip(event_times, event_names))\n",
    "    \n",
    "    # Define containers for all metrics.\n",
    "    metrics = {\n",
    "        'd_prime': [],\n",
    "        'c_score': [],\n",
    "        'participation': [],\n",
    "        'total_hits': [],\n",
    "        'total_mistakes': [],\n",
    "        'hit_rate': [],\n",
    "        'false_alarm_rate': []\n",
    "    }\n",
    "    \n",
    "    # The performance functions expect event counts with keys as defined below.\n",
    "    required_keys = ['hit', 'miss', 'mistake', 'cor_reject']\n",
    "    \n",
    "    # def get_window_counts(window_events, current_time, tau):\n",
    "    #     \"\"\"\n",
    "    #     Compute weighted counts for the events in the window.\n",
    "    #     Newer events (closer to current_time) receive higher weights.\n",
    "    #     Weight is computed as: exp(-(current_time - event_time) / tau)\n",
    "    #     \"\"\"\n",
    "    #     weighted_counts = {key: 0.0 for key in required_keys}\n",
    "    #     for event_time, event_name in window_events:\n",
    "    #         # Compute the age of the event relative to the current time\n",
    "    #         dt = current_time - event_time\n",
    "    #         # Exponential decay weighting; adjust tau to change decay rate.\n",
    "    #         weight = np.exp(-dt / tau)\n",
    "    #         event_lower = event_name.lower()\n",
    "    #         if event_lower in weighted_counts:\n",
    "    #             weighted_counts[event_lower] += weight\n",
    "    #     return weighted_counts\n",
    "    \n",
    "    def get_window_counts(window_events):\n",
    "        \"\"\"\n",
    "        Compute unweighted counts for the events in the window.\n",
    "        Each event in the window contributes 1.\n",
    "        \"\"\"\n",
    "        return {key: sum(1 for _, ev in window_events if ev.lower() == key)\n",
    "            for key in required_keys}\n",
    "\n",
    "    \n",
    "    # Use a two-pointer sliding window for efficiency.\n",
    "    left = 0\n",
    "    for right in range(len(events)):\n",
    "        current_time = events[right][0]\n",
    "        # Advance left pointer to maintain window: [current_time - window_time, current_time]\n",
    "        while left < right and events[left][0] < current_time - window_time:\n",
    "            left += 1\n",
    "        window_events = events[left:right+1]\n",
    "        # counts = get_window_counts(window_events, current_time, tau)\n",
    "        counts = get_window_counts(window_events)\n",
    "        \n",
    "        # Calculate metrics using the provided functions (assumed imported via performance_funcs)\n",
    "        dp = performance_funcs.d_prime(counts)\n",
    "        cs = performance_funcs.c_score(counts)\n",
    "        part = performance_funcs.participation(counts)\n",
    "        th = performance_funcs.total_hits(counts)\n",
    "        tm = performance_funcs.total_mistakes(counts)\n",
    "        hr = performance_funcs.hit_rate(counts)\n",
    "        far = performance_funcs.false_alarm_rate(counts)\n",
    "        \n",
    "        # If a metric returns None, substitute with -1.0 (or any appropriate placeholder)\n",
    "        metrics['d_prime'].append(dp if dp is not None else -1.0)\n",
    "        metrics['c_score'].append(cs if cs is not None else -1.0)\n",
    "        metrics['participation'].append(part)\n",
    "        metrics['total_hits'].append(th)\n",
    "        metrics['total_mistakes'].append(tm)\n",
    "        metrics['hit_rate'].append(hr)\n",
    "        metrics['false_alarm_rate'].append(far)\n",
    "    \n",
    "    return event_times, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_mice  = [\"79\", \"85\", \"87\", \"125\", \"127\", \"131\", \"135\", \"137\", \"145\", \"147\", \"161\", \"77\", \"129\", \"143\", \"159\", \"171\", \"173\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common time grid (0 to 30 minutes) and sliding window duration\n",
    "window_time = 300  # in seconds\n",
    "time_start = 0  \n",
    "time_end = 30 * 60  # 30 minutes in seconds\n",
    "common_time_grid = np.linspace(time_start, time_end, 1000)\n",
    "\n",
    "# Define the dose conditions and the metric names to plot.\n",
    "dose_conditions = [None, '0.1', '0.5', '2.0']\n",
    "metric_keys = ['total_hits', 'd_prime', 'c_score', 'participation', 'total_mistakes', 'hit_rate', 'false_alarm_rate']\n",
    "\n",
    "\n",
    "color_order = ['C2', 'C0', 'C1', 'C3']\n",
    "# For each performance metric, create a separate plot.\n",
    "for metric_name in metric_keys:\n",
    "    plt.figure()  # New figure for each metric\n",
    "    for dose, color_used in zip(dose_conditions, color_order):\n",
    "        interp_metric_list = []\n",
    "        sessions_with_data = 0\n",
    "\n",
    "        # Loop through sessions and filter by dose and genotype.\n",
    "        for session in sessions:\n",
    "            if session.mouse_id not in include_mice:\n",
    "                continue\n",
    "            if session.genotype != 'Wildtype':\n",
    "                continue\n",
    "            curr_dose = session.drug_infos[0]['dose']\n",
    "            if curr_dose != dose:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                event_times, sess_metrics = running_performance_all(session, window_time)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping session due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if event_times is None or len(event_times) <= 1:\n",
    "                continue\n",
    "\n",
    "            # Get relative times based on blank image time\n",
    "            blank_image_time = session.dfs.data['raw'].iloc[session.cpt]['sec_from_zero']\n",
    "            relative_times = event_times - blank_image_time\n",
    "\n",
    "            # Get the metric values for the current metric\n",
    "            metric_values = sess_metrics[metric_name]\n",
    "\n",
    "            # Interpolate onto the common time grid\n",
    "            try:\n",
    "                interp_func = interp1d(relative_times, metric_values, kind='linear', fill_value=\"extrapolate\")\n",
    "                interp_values = interp_func(common_time_grid)\n",
    "                interp_metric_list.append(interp_values)\n",
    "                sessions_with_data += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping session due to interpolation error: {e}\")\n",
    "                continue\n",
    "\n",
    "        if sessions_with_data == 0:\n",
    "            print(f\"No valid sessions for dose {dose} on metric {metric_name}.\")\n",
    "            continue\n",
    "\n",
    "        # Convert to a NumPy array and compute the mean, SEM, and 95% CI.\n",
    "        interp_metric_array = np.array(interp_metric_list)\n",
    "        mean_metric = np.mean(interp_metric_array, axis=0)\n",
    "        sem_metric = np.std(interp_metric_array, axis=0) / np.sqrt(sessions_with_data)\n",
    "        ci_metric = 1.96 * sem_metric  # 95% confidence interval\n",
    "\n",
    "        # Plot mean and fill the area for the CI (convert time to minutes)\n",
    "        plt.plot(common_time_grid / 60, mean_metric, label=f\"{dose}\", color=color_used)\n",
    "        plt.fill_between(common_time_grid / 60, mean_metric - ci_metric, mean_metric + ci_metric, alpha=0.2, color=color_used)\n",
    "\n",
    "    plt.title(f\"Running Performance: {metric_name} (window={window_time} seconds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Time relative to blank image (minutes)\")\n",
    "    plt.ylabel(metric_name)\n",
    "\n",
    "    # Define filenames based on the metric name.\n",
    "    png_filename = f\"Running_Performance_{metric_name}_300_seconds_wt.png\"\n",
    "    pdf_filename = f\"Running_Performance_{metric_name}_300_seconds_wt.pdf\"\n",
    "    svg_filename = f\"Running_Performance_{metric_name}_300_seconds_wt.svg\"\n",
    "\n",
    "    # Save the figure in both formats.\n",
    "    plt.savefig(png_filename, format='png', dpi=300)\n",
    "    plt.savefig(pdf_filename, format='pdf')\n",
    "    plt.savefig(svg_filename, format='svg')\n",
    "\n",
    "    # Then display the plot in your notebook.\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiberphoto-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
