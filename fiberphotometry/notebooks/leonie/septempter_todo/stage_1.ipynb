{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "# Custom modules\n",
    "from main import load_and_prepare_sessions\n",
    "from processing.session_sampling import MiceAnalysis\n",
    "from data.mouse import create_mice_dict\n",
    "from analysis.timepoint_analysis import sample_signals_and_metrics, collect_sessions_data\n",
    "\n",
    "# Config and constants\n",
    "from config import all_event_types, all_brain_regions\n",
    "import config\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Signal processing and statistical tools\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.stats as stats\n",
    "from itertools import product\n",
    "\n",
    "# Utility libraries\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import FloatProgress\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stage in ['stage1', 'stage2', 'stage3', 'stage4']:\n",
    "#     for phase in ['pre', 'post']:\n",
    "#         curr_sessions = load_and_prepare_sessions(\"../../../../Gq-DREADD_CPT_Training_Stages\", load_from_pickle=True, remove_bad_signal_sessions=True,\n",
    "#                                                   pickle_name=f'sessions_{stage}_{phase}')\n",
    "        #title = stage + ' ' + phase\n",
    "        # for session in tqdm(curr_sessions):\n",
    "        #     for brain_reg in session.brain_regions:\n",
    "        #         pass\n",
    "                # # Step 3: Create a Plotly figure object for subplots\n",
    "                # # Adjust rows and cols based on your layout needs\n",
    "                # fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "                # title = f\"genotype: {session.genotype}, dose: {session.drug_info['dose']}, brain region: {brain_reg}\\\n",
    "                #     \\n{session.trial_id}, {stage}, {phase}\"\n",
    "                # plot_session_events_and_signal(session, brain_reg, fig, row=1, col=1, title_suffix=title)\n",
    "                # #fig.write_image(f\"{session.mouse_id}_{session.trial_id}_{brain_reg}.png\")\n",
    "                # #fig.show()\n",
    "\n",
    "                # #fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "                # #plot_session_events_and_signal(session, brain_reg, fig, row=1, col=1, title_suffix=title, smooth=True)\n",
    "                # #fig.write_image(f\"{session.mouse_id}_{session.trial_id}_{brain_reg}.png\")\n",
    "                # curr_fname = f\"{session.mouse_id}_{session.trial_id}_{brain_reg}_{stage}_{phase}.html\"\n",
    "                # print(curr_fname)\n",
    "                # fig.write_html(curr_fname)\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mice_sessions = load_and_prepare_sessions(\"../../../../Gq-DREADD_CPT_Training_Stages\", load_from_pickle=True, remove_bad_signal_sessions=True,\n",
    "                                                pickle_name=f'sessions_two_stage1_pre')\n",
    "first_mice_ids = [s.mouse_id for s in first_mice_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_reg_to_color = {'LH': 'orange',\n",
    "                      'mPFC': 'cornflowerblue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_genotypes(sessions, mice_gen_dict):\n",
    "    \"\"\"\n",
    "    Updates the genotypes for a list of sessions based on the provided genotype mapping.\n",
    "    Prints whether the genotypes are valid ('TH-Cre', 'Wildtype') \n",
    "    and the number of genotype changes made.\n",
    "\n",
    "    Parameters:\n",
    "    - sessions: A list of session objects to process.\n",
    "    - mice_gen_dict: A dictionary mapping mouse IDs to new genotypes.\n",
    "    \"\"\"\n",
    "    geno_mapping = {\n",
    "        \"Cre\": \"TH-Cre\",\n",
    "        \"WT\": \"Wildtype\"\n",
    "    }\n",
    "    # Map mice_gen_dict to use TH-Cre and Wildtype\n",
    "    mapped_genotypes = {k: geno_mapping[v] for k, v in mice_gen_dict.items()}\n",
    "    \n",
    "    # Initialize counters and trackers\n",
    "    valid_genotypes = {'TH-Cre', 'Wildtype'}\n",
    "    all_genotypes = set()\n",
    "    genotype_changes = 0\n",
    "\n",
    "    for session in sessions:\n",
    "        original_genotype = session.genotype\n",
    "        int_id = int(session.mouse_id)\n",
    "        \n",
    "        if int_id in mapped_genotypes:\n",
    "            session.genotype = mapped_genotypes[int_id]\n",
    "            # Count changes if the genotype was updated\n",
    "            if session.genotype != original_genotype:\n",
    "                genotype_changes += 1\n",
    "        \n",
    "        all_genotypes.add(session.genotype)\n",
    "    \n",
    "    # Print results\n",
    "    if all_genotypes.issubset(valid_genotypes):\n",
    "        print(f\"Valid genotypes found: {all_genotypes}\")\n",
    "    else:\n",
    "        print(f\"Invalid genotypes found: {all_genotypes}\")\n",
    "    \n",
    "    print(f\"Genotype changes made: {genotype_changes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_gen_dict = {\n",
    "    69: \"Cre\",\n",
    "    71: \"WT\",\n",
    "    73: \"Cre\",\n",
    "    75: \"WT\",\n",
    "    77: \"Cre\",\n",
    "    79: \"WT\",\n",
    "    85: \"WT\",\n",
    "    87: \"WT\",\n",
    "    135: \"WT\",\n",
    "    137: \"WT\",\n",
    "    139: \"Cre\",\n",
    "    133: \"WT\",\n",
    "    127: \"WT\",\n",
    "    125: \"WT\",\n",
    "    129: \"Cre\",\n",
    "    131: \"WT\",\n",
    "    143: \"Cre\",\n",
    "    145: \"WT\",\n",
    "    147: \"WT\",\n",
    "    157: \"Cre\",\n",
    "    159: \"Cre\",\n",
    "    161: \"WT\",\n",
    "    171: \"Cre\",\n",
    "    173: \"Cre\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid genotypes found: {'Wildtype', 'TH-Cre'}\n",
      "Genotype changes made: 1\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 1\n",
      "[INFO] stage1: 7 common mouse IDs across phases.\n",
      "[INFO] stage1 - pre: 7 sessions after filtering.\n",
      "[INFO] stage1 - post: 7 sessions after filtering.\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 0\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 2\n",
      "[INFO] stage2: 13 common mouse IDs across phases.\n",
      "[INFO] stage2 - pre: 15 sessions after filtering.\n",
      "[INFO] stage2 - post: 13 sessions after filtering.\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 1\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 0\n",
      "[INFO] stage3: 20 common mouse IDs across phases.\n",
      "[INFO] stage3 - pre: 20 sessions after filtering.\n",
      "[INFO] stage3 - post: 20 sessions after filtering.\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 0\n",
      "Valid genotypes found: {'TH-Cre', 'Wildtype'}\n",
      "Genotype changes made: 0\n",
      "[INFO] stage4: 6 common mouse IDs across phases.\n",
      "[INFO] stage4 - pre: 6 sessions after filtering.\n",
      "[INFO] stage4 - post: 6 sessions after filtering.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Instead of defaultdict(dict), we need a nested structure keyed by (event, brain_reg, genotype).\n",
    "# The value remains a dict keyed by (stage, phase).\n",
    "signals_grouped = defaultdict(dict)\n",
    "\n",
    "stages = ['stage1', 'stage2', 'stage3', 'stage4']\n",
    "phases = ['pre', 'post']\n",
    "\n",
    "for stage in stages:\n",
    "    # Temporary storage for sessions in each phase\n",
    "    phase_sessions = {}\n",
    "    \n",
    "    # Step 1: Load all sessions for the current stage across all phases\n",
    "    for phase in phases:\n",
    "        pickle_name = f'sessions_two_{stage}_{phase}'\n",
    "        \n",
    "        # Load and prepare sessions\n",
    "        sessions = load_and_prepare_sessions(\n",
    "            \"../../../../Gq-DREADD_CPT_Training_Stages\",\n",
    "            load_from_pickle=True,\n",
    "            remove_bad_signal_sessions=True,\n",
    "            pickle_name=pickle_name\n",
    "        )\n",
    "        \n",
    "        # Update genotypes in-place\n",
    "        update_genotypes(sessions, mice_gen_dict)\n",
    "        phase_sessions[phase] = sessions\n",
    "    \n",
    "    # Step 2: Compute the intersection of mouse IDs across phases\n",
    "    mouse_ids_pre = set(s.mouse_id for s in phase_sessions['pre'])\n",
    "    mouse_ids_post = set(s.mouse_id for s in phase_sessions['post'])\n",
    "    intersection_mouse_ids = mouse_ids_pre.intersection(mouse_ids_post)\n",
    "\n",
    "    print(f\"[INFO] {stage}: {len(intersection_mouse_ids)} common mouse IDs across phases.\")\n",
    "    \n",
    "    # Step 3: Iterate over each phase and filter sessions by the intersection of mouse IDs\n",
    "    for phase in phases:\n",
    "        sessions = phase_sessions[phase]\n",
    "        filtered_sessions = [s for s in sessions if s.mouse_id in intersection_mouse_ids]\n",
    "        \n",
    "        print(f\"[INFO] {stage} - {phase}: {len(filtered_sessions)} sessions after filtering.\")\n",
    "        \n",
    "        # Step 4: Group signals by (event, brain_reg, genotype)\n",
    "        for event in all_event_types:\n",
    "            for brain_reg in all_brain_regions:\n",
    "                # 1) Gather only those sessions that have the current genotype\n",
    "                #    We'll group them by genotype, so we can sample separately.\n",
    "                genotype_groups = defaultdict(list)\n",
    "                for sess in filtered_sessions:\n",
    "                    genotype_groups[sess.genotype].append(sess)\n",
    "\n",
    "                # 2) For each genotype, sample signals and store them\n",
    "                for genotype, geno_sess_list in genotype_groups.items():\n",
    "                    sampled = sample_signals_and_metrics(\n",
    "                        geno_sess_list,\n",
    "                        brain_reg,\n",
    "                        'G', \n",
    "                        event, \n",
    "                        weight_method='events'\n",
    "                    )\n",
    "                    if sampled:\n",
    "                        all_signals = sampled[0]\n",
    "                        \n",
    "                        # Now store under (event, brain_reg, genotype) instead of just (event, brain_reg)\n",
    "                        key = (event, brain_reg, genotype)\n",
    "                        # If you haven't initialized this sub-dict yet, do so now\n",
    "                        if key not in signals_grouped:\n",
    "                            signals_grouped[key] = {}\n",
    "                        # Then store data keyed by (stage, phase)\n",
    "                        signals_grouped[key][(stage, phase)] = all_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_plot_signals(all_signals, event_type, brain_region, smoothing_len=10, title_suffix=None):\n",
    "    # Assuming all_signals is predefined\n",
    "    signals = all_signals\n",
    "\n",
    "    interval_start = config.peak_interval_config[\"interval_start\"]\n",
    "    interval_end = config.peak_interval_config[\"interval_end\"]\n",
    "    fps = config.PLOTTING_CONFIG['fps']\n",
    "    \n",
    "    xs = np.arange(-interval_start, interval_end) / fps\n",
    "    \n",
    "    # Smooth the mean signal\n",
    "    ys = np.mean(signals, axis=0)\n",
    "    window = np.ones(smoothing_len) / smoothing_len\n",
    "    ys = np.convolve(ys, window, 'same')\n",
    "\n",
    "    # Calculate the standard deviation of the mean\n",
    "    std_signal = np.std(signals, axis=0) / np.sqrt(len(signals))\n",
    "\n",
    "    # Use scipy.stats.norm.interval to get the 95% confidence interval\n",
    "    alpha = 0.95\n",
    "    ci_lower, ci_upper = stats.norm.interval(alpha, loc=ys, scale=std_signal)\n",
    "\n",
    "    # The lower and upper bounds\n",
    "    lb = ci_lower.min()\n",
    "    ub = ci_upper.max()\n",
    "\n",
    "    ylim = (lb, ub)\n",
    "    \n",
    "    # Assuming brain_reg_to_color is predefined\n",
    "    color = brain_reg_to_color[brain_region]\n",
    "\n",
    "    if title_suffix is None:\n",
    "        title_suffix = ''\n",
    "    plt.figure(dpi=300)\n",
    "    plt.plot(xs, ys, color=color, label='Mean Signal')\n",
    "    plt.fill_between(xs, ci_lower, ci_upper, color=color, alpha=0.2, label='95% CI')\n",
    "    plt.ylim(ylim)\n",
    "    title_name = f'{event_type}, {brain_region}, {title_suffix}, (n = {len(signals)})'\n",
    "    plt.title(title_name)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('z-score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    # plt.savefig(title_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def preprocess_and_plot_signals(all_signals, event_type, brain_region, smoothing_len=10, title_suffix=None, ax=None):\n",
    "    \"\"\"\n",
    "    Preprocess and plot signals on the given Axes.\n",
    "\n",
    "    Parameters:\n",
    "    - all_signals: numpy array of signals\n",
    "    - event_type: string indicating the event type\n",
    "    - brain_region: string indicating the brain region\n",
    "    - smoothing_len: integer for smoothing window length\n",
    "    - title_suffix: additional string for the plot title\n",
    "    - ax: matplotlib Axes object to plot on\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(dpi=300)\n",
    "\n",
    "    signals = all_signals\n",
    "\n",
    "    interval_start = config.peak_interval_config[\"interval_start\"]\n",
    "    interval_end = config.peak_interval_config[\"interval_end\"]\n",
    "    fps = config.PLOTTING_CONFIG['cpt']['fps']\n",
    "\n",
    "    xs = np.arange(-interval_start, interval_end) / fps\n",
    "\n",
    "    # Smooth the mean signal\n",
    "    ys = np.mean(signals, axis=0)\n",
    "    window = np.ones(smoothing_len) / smoothing_len\n",
    "    ys = np.convolve(ys, window, 'same')\n",
    "\n",
    "    # Calculate the standard deviation of the mean\n",
    "    std_signal = np.std(signals, axis=0) / np.sqrt(len(signals))\n",
    "\n",
    "    # Use scipy.stats.norm.interval to get the 95% confidence interval\n",
    "    alpha = 0.95\n",
    "    ci_lower, ci_upper = stats.norm.interval(alpha, loc=ys, scale=std_signal)\n",
    "\n",
    "    # Assuming brain_reg_to_color is predefined\n",
    "    color = brain_reg_to_color.get(brain_region, 'blue')  # Default to 'blue' if not found\n",
    "\n",
    "    if title_suffix is None:\n",
    "        title_suffix = ''\n",
    "    \n",
    "    ax.plot(xs, ys, color=color, label='Mean Signal')\n",
    "    ax.fill_between(xs, ci_lower, ci_upper, color=color, alpha=0.2, label='95% CI')\n",
    "    \n",
    "    title_name = f'{event_type}, {brain_region}, {title_suffix}, (n = {len(signals)})'\n",
    "    ax.set_title(title_name, fontsize=10)\n",
    "    ax.set_xlabel('Time (s)', fontsize=8)\n",
    "    ax.set_ylabel('z-score', fontsize=8)\n",
    "    ax.legend(fontsize=6)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_y_limits = 'row'  # or 'global'\n",
    "\n",
    "for sync_y_limits in ['row', 'global']:\n",
    "    for (event, brain_reg, genotype), stage_phase_signals in signals_grouped.items():\n",
    "        # Create a figure with 4 rows (stages) and 2 columns (phases)\n",
    "        fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 15), dpi=300, sharex=True, sharey=False)\n",
    "        fig_title = f'Event: {event} | Brain Region: {brain_reg} | Genotype: {genotype}'\n",
    "        fig.suptitle(fig_title, fontsize=16)\n",
    "        \n",
    "        # Prepare for optional Y-limit synchronization\n",
    "        if sync_y_limits == 'global':\n",
    "            all_y_mins, all_y_maxs = [], []\n",
    "        elif sync_y_limits == 'row':\n",
    "            row_y_mins = [[] for _ in range(4)]\n",
    "            row_y_maxs = [[] for _ in range(4)]\n",
    "        else:\n",
    "            raise ValueError(\"sync_y_limits must be either 'global' or 'row'\")\n",
    "\n",
    "        for i, stage in enumerate(['stage1', 'stage2', 'stage3', 'stage4']):\n",
    "            for j, phase in enumerate(['pre', 'post']):\n",
    "                ax = axes[i][j]\n",
    "                key_stage_phase = (stage, phase)\n",
    "                \n",
    "                if key_stage_phase in stage_phase_signals:\n",
    "                    all_signals = stage_phase_signals[key_stage_phase]\n",
    "                    title_suffix = f'{stage}, {phase}'\n",
    "                    preprocess_and_plot_signals(\n",
    "                        all_signals,\n",
    "                        event_type=event,\n",
    "                        brain_region=brain_reg,\n",
    "                        smoothing_len=10,\n",
    "                        title_suffix=title_suffix,\n",
    "                        ax=ax\n",
    "                    )\n",
    "                    current_ylim = ax.get_ylim()\n",
    "                    if sync_y_limits == 'global':\n",
    "                        all_y_mins.append(current_ylim[0])\n",
    "                        all_y_maxs.append(current_ylim[1])\n",
    "                    elif sync_y_limits == 'row':\n",
    "                        row_y_mins[i].append(current_ylim[0])\n",
    "                        row_y_maxs[i].append(current_ylim[1])\n",
    "                else:\n",
    "                    # No data for this stage/phase\n",
    "                    ax.axis('off')\n",
    "                    ax.set_title(f'{stage}, {phase}\\nNo Data', fontsize=10)\n",
    "\n",
    "        # Adjust Y-axis limits (same logic as before)\n",
    "        if sync_y_limits == 'global':\n",
    "            if all_y_mins and all_y_maxs:\n",
    "                global_min = min(all_y_mins)\n",
    "                global_max = max(all_y_maxs)\n",
    "                for ax in axes.flat:\n",
    "                    if ax.has_data():\n",
    "                        ax.set_ylim(global_min, global_max)\n",
    "        elif sync_y_limits == 'row':\n",
    "            for row in range(4):\n",
    "                if row_y_mins[row] and row_y_maxs[row]:\n",
    "                    row_min = min(row_y_mins[row])\n",
    "                    row_max = max(row_y_maxs[row])\n",
    "                    for col in range(2):\n",
    "                        ax = axes[row][col]\n",
    "                        if ax.has_data():\n",
    "                            ax.set_ylim(row_min, row_max)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(f\"plot_event_{event}_{brain_reg}_{genotype}_{sync_y_limits}_event_agg.png\")\n",
    "        #plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_br_event_count(session, br, event):\n",
    "    total = 0\n",
    "    maybe_signal_info = session.signal_info.get((br, event))\n",
    "    if maybe_signal_info:\n",
    "        total += maybe_signal_info['signal_matrix'].shape[0]\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 pre 8\n",
      "stage1 post 23\n",
      "stage2 pre 16\n",
      "stage2 post 24\n",
      "stage3 pre 23\n",
      "stage3 post 21\n",
      "stage4 pre 7\n",
      "stage4 post 6\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Group Signals\n",
    "signals_grouped = defaultdict(dict)\n",
    "\n",
    "for stage in ['stage1', 'stage2', 'stage3', 'stage4']:\n",
    "    for phase in ['pre', 'post']:\n",
    "        pickle_name = f'sessions_two_{stage}_{phase}'\n",
    "        curr_sessions = load_and_prepare_sessions(\n",
    "            \"../../../../Gq-DREADD_CPT_Training_Stages\",\n",
    "            load_from_pickle=True,\n",
    "            remove_bad_signal_sessions=True,\n",
    "            pickle_name=pickle_name\n",
    "        )\n",
    "        print(stage, phase, len(curr_sessions))\n",
    "        # print(stage, phase, [(s.mouse_id, session_br_event_count(s, 'mPFC', 'dispimg')) for s in curr_sessions])\n",
    "                              #if session_br_event_count(s, 'mPFC', 'dispimg') < 100])\n",
    "        \n",
    "        # # Filter sessions by mouse IDs\n",
    "        # if stage == 'stage1':\n",
    "        #     curr_sessions = [s for s in curr_sessions if s.mouse_id in first_mice_ids]\n",
    "        \n",
    "        # for event in all_event_types:\n",
    "        #     for brain_reg in all_brain_regions:\n",
    "        #         key = (event, brain_reg)\n",
    "        #         if sample_signals_and_metrics(curr_sessions, event, brain_reg, weight_method='mice'):\n",
    "        #             all_signals = sample_signals_and_metrics(curr_sessions, event, brain_reg, weight_method='mice')[0]\n",
    "        #             signals_grouped[key][(stage, phase)] = all_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sund",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
