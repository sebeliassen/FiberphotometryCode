{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb7fffaa",
   "metadata": {},
   "source": [
    "# Demo 1: Loading and Preparing a Baseline Experiment\n",
    "\n",
    "**Goal:** This notebook demonstrates the fundamental workflow for loading raw experimental data into our analysis pipeline. We'll take a 'Baseline' experiment, load each session into a special `Session` object, synchronize the photometry and behavioral data, and prepare it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7978b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b149b3",
   "metadata": {},
   "source": [
    "First we load in the library. This is mostly boilerplate, and a simple import fiberphotometry will suffice in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b4514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pytest\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from fiberphotometry.config import PLOTTING_CONFIG\n",
    "from fiberphotometry.data.data_loading import DataContainer, load_all_sessions\n",
    "from fiberphotometry.data.session_loading import populate_containers\n",
    "from fiberphotometry.data.syncer import sync_session\n",
    "from fiberphotometry.data.timepoint_processing import create_event_idxs_container_for_sessions\n",
    "from fiberphotometry.processing.plotting_setup import PlottingSetup\n",
    "from fiberphotometry.processing.signal_info_setup import assign_sessions_signal_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7f67c",
   "metadata": {},
   "source": [
    "Define the path from which our trial is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee584c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_path = Path(\"/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714cb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data files in: T20_31.33.43.45\n",
      "  - DigInput_A2023-02-09T13_48_22.csv\n",
      "  - DigInput_B2023-02-09T13_48_22.csv\n",
      "  - DigInput_C2023-02-09T13_48_22.csv\n",
      "  - DigInput_D2023-02-09T13_48_22.csv\n",
      "  - RAW_A.csv\n",
      "  - RAW_B.csv\n",
      "  - RAW_C.csv\n",
      "  - RAW_D.csv\n",
      "  - T20_trial_guide.csv\n",
      "  - T20_trial_guide.xlsx\n",
      "  - photometry_data_combined_SetupA_2023-02-09T13_48_23.csv\n",
      "  - photometry_data_combined_SetupB_2023-02-09T13_48_23.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Let's look at the raw files for the first trial to see what we're starting with.\n",
    "try:\n",
    "    first_dir = next(baseline_path.iterdir())\n",
    "    print(f\"Raw data files in: {first_dir.name}\")\n",
    "    for fname in sorted(os.listdir(first_dir)):\n",
    "        print(f\"  - {fname}\")\n",
    "except StopIteration:\n",
    "    print(\"No directories found in the baseline path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba395d8",
   "metadata": {},
   "source": [
    "Here you see an example of what data our folder contains. This includes syncing files (DigInput*.csv), CPT records (RAW*.csv), photometry data (photometry_data_combined*.csv) and the manually created trial guides (T*trial_guides.csv). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1720f9c",
   "metadata": {},
   "source": [
    "### Creating Session Objects\n",
    "\n",
    "The `load_all_sessions` function scans the directories and creates a list of `Session` objects. Each object acts as a container for all the data and metadata related to a single recording session, making it easy to manage. Assuming everything is structured according to the data collection standard, this can be simply run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4078d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial directories:   0%|          | 0/10 [00:00<?, ?it/s]/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T1 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T1_23.25.29.e. Using 'T1_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "Processing trial directories:  10%|█         | 1/10 [00:00<00:01,  4.57it/s]/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T2 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T2_23.25.29.e_2. Using 'T2_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T3 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T3_23.25.29.e_4. Using 'T3_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T4 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T4_31.33.35.37. Using 'T4_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T5 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T5_31.33.35.37_3. Using 'T5_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T6 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T6_31.33.35.37_4. Using 'T6_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T7 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T7_39.e.43.45. Using 'T7_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T8 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T8_39.41.43.45_2. Using 'T8_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T9 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T9_e.41.43.45_3. Using 'T9_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "/Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/data/data_loading.py:390: UserWarning: Both XLSX and CSV trial‐guide files found for T10 in /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T10_47.49.e.53_2. Using 'T10_trial_guide.xlsx'.\n",
      "  warnings.warn(\n",
      "Processing trial directories: 100%|██████████| 10/10 [00:00<00:00, 32.18it/s]\n"
     ]
    }
   ],
   "source": [
    "sessions = load_all_sessions(\n",
    "            baseline_dir=str(baseline_path),\n",
    "            session_type=\"cpt\",\n",
    "            first_n_dirs=10,\n",
    "            remove_bad_signal_sessions=True\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b07b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse_id 23 trial_id T1_23.25.29.e\n",
      "mouse_id 25 trial_id T2_23.25.29.e_2\n",
      "mouse_id 23 trial_id T3_23.25.29.e_4\n",
      "mouse_id 25 trial_id T3_23.25.29.e_4\n",
      "mouse_id 31 trial_id T4_31.33.35.37\n",
      "mouse_id 35 trial_id T4_31.33.35.37\n",
      "mouse_id 37 trial_id T4_31.33.35.37\n",
      "mouse_id 35 trial_id T5_31.33.35.37_3\n",
      "mouse_id 37 trial_id T5_31.33.35.37_3\n",
      "mouse_id 33 trial_id T6_31.33.35.37_4\n",
      "mouse_id 39 trial_id T7_39.e.43.45\n",
      "mouse_id 45 trial_id T7_39.e.43.45\n",
      "mouse_id 39 trial_id T8_39.41.43.45_2\n",
      "mouse_id 43 trial_id T8_39.41.43.45_2\n",
      "mouse_id 47 trial_id T10_47.49.e.53_2\n",
      "mouse_id 49 trial_id T10_47.49.e.53_2\n"
     ]
    }
   ],
   "source": [
    "for session in sessions:\n",
    "    print('mouse_id', session.mouse_id, 'trial_id', session.trial_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6dccd",
   "metadata": {},
   "source": [
    "The function automatically picks up all columns in the session guide (with some reserved exceptions) making it easy to add new attributes like genotype, weight or age. Below we print all the attributes that the sessions have picked up from the trial guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229b3a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brain_regions: [('DLS', 'left', 'G'), ('DMS', 'right', 'G')]\n",
      "chamber_id: A\n",
      "dfs: <fiberphotometry.data.data_loading.DataContainer object at 0x15109e7d0>\n",
      "dig_input: 0\n",
      "drug_infos: []\n",
      "fiber_to_region: {'0': ('DLS', 'left', 'G'), '2': ('DMS', 'right', 'G')}\n",
      "genotype: WT\n",
      "mouse_id: 23\n",
      "notes: nan\n",
      "remove_bad_signal_sessions: True\n",
      "session_type: cpt\n",
      "setup_id: A\n",
      "task: CPT_stage4_baseline\n",
      "trial_dir: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T1_23.25.29.e\n",
      "trial_id: T1_23.25.29.e\n"
     ]
    }
   ],
   "source": [
    "obj = sessions[0]\n",
    "\n",
    "for name in dir(obj):\n",
    "    if name.startswith(\"__\"):\n",
    "        continue\n",
    "    value = getattr(obj, name)\n",
    "    if callable(value) or name == 'session_guide':\n",
    "        continue\n",
    "    print(f\"{name}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93438abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sessions and their corresponding mouse IDs:\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T1_23.25.29.e, Mouse ID: 23\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T2_23.25.29.e_2, Mouse ID: 25\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T3_23.25.29.e_4, Mouse ID: 23\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T3_23.25.29.e_4, Mouse ID: 25\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T4_31.33.35.37, Mouse ID: 31\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T4_31.33.35.37, Mouse ID: 35\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T4_31.33.35.37, Mouse ID: 37\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T5_31.33.35.37_3, Mouse ID: 35\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T5_31.33.35.37_3, Mouse ID: 37\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T6_31.33.35.37_4, Mouse ID: 33\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T7_39.e.43.45, Mouse ID: 39\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T7_39.e.43.45, Mouse ID: 45\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T8_39.41.43.45_2, Mouse ID: 39\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T8_39.41.43.45_2, Mouse ID: 43\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T10_47.49.e.53_2, Mouse ID: 47\n",
      "Directory: /Users/fsp585/Desktop/GetherLabCode/FiberphotometryCode/src/Baseline/T10_47.49.e.53_2, Mouse ID: 49\n"
     ]
    }
   ],
   "source": [
    "# Now we have a list of session objects. Let's see what was loaded.\n",
    "print(\"Loaded sessions and their corresponding mouse IDs:\")\n",
    "for s in sessions:\n",
    "    # This info is automatically parsed from the directory and trial guide files.\n",
    "    print(f\"Directory: {s.trial_dir}, Mouse ID: {s.mouse_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837c5c6",
   "metadata": {},
   "source": [
    "## Step 2: Populating the Session Objects\n",
    "\n",
    "Our `Session` objects currently hold metadata, but the actual experimental data (from the `.csv` files) isn't loaded into memory yet.\n",
    "\n",
    "The `populate_containers` function handles this critical step. It finds the raw data files on the disk and loads them into pandas DataFrames, \"filling\" each session with the data it needs for analysis.\n",
    "\n",
    "The next cell will demonstrate this by showing the row counts for each data table change from **\"Not loaded\"** to being filled with thousands of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab7387cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. Row Counts Before 'populate_containers' (Simulated Fresh Session)\n",
      "\n",
      "Number of rows in each data table:\n",
      "- raw: Not loaded\n",
      "- ttl: Not loaded\n",
      "- phot_415: Not loaded\n",
      "- phot_470: Not loaded\n",
      "\n",
      "## 2. Row Counts After 'populate_containers'\n",
      "\n",
      "Number of rows in each data table:\n",
      "- raw: 8802\n",
      "- ttl: 66\n",
      "- phot_415: 103007\n",
      "- phot_470: 103008\n",
      "\n",
      "## 3. The Delta (The Data We Filled In) ✅\n",
      "\n",
      "The function read the raw data files from disk and filled the data tables with rows.\n"
     ]
    }
   ],
   "source": [
    "from fiberphotometry.data.data_loading import DataContainer # Required for the reset\n",
    "\n",
    "# Use a single session for the demonstration\n",
    "s0_for_populate_demo = sessions[0]\n",
    "# Define the data tables we expect the function to load\n",
    "expected_dfs = ['raw', 'ttl', 'phot_415', 'phot_470']\n",
    "\n",
    "# ---\n",
    "# 1. The \"Before\" State\n",
    "# ---\n",
    "print(\"## 1. Row Counts Before 'populate_containers' (Simulated Fresh Session)\\n\")\n",
    "\n",
    "# To ensure the demo works correctly, we'll simulate a fresh session\n",
    "# by replacing its container with a new, empty one.\n",
    "s0_for_populate_demo.dfs = DataContainer()\n",
    "\n",
    "print(\"Number of rows in each data table:\")\n",
    "for name in expected_dfs:\n",
    "    # Before populating, the data tables don't exist in the container yet\n",
    "    try:\n",
    "        num_rows = len(s0_for_populate_demo.dfs.data[name])\n",
    "    except KeyError:\n",
    "        num_rows = \"Not loaded\"\n",
    "    print(f\"- {name}: {num_rows}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# 2. Run the populate_containers function\n",
    "# ---\n",
    "populate_containers([s0_for_populate_demo])\n",
    "\n",
    "\n",
    "# ---\n",
    "# 3. The \"After\" State\n",
    "# ---\n",
    "print(\"\\n## 2. Row Counts After 'populate_containers'\\n\")\n",
    "print(\"Number of rows in each data table:\")\n",
    "for name in expected_dfs:\n",
    "    try:\n",
    "        num_rows = len(s0_for_populate_demo.dfs.data[name])\n",
    "    except KeyError:\n",
    "        num_rows = \"Not loaded\"\n",
    "    print(f\"- {name}: {num_rows}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# 4. The Delta\n",
    "# ---\n",
    "print(\"\\n## 3. The Delta (The Data We Filled In) ✅\\n\")\n",
    "print(\"The function read the raw data files from disk and filled the data tables with rows.\")\n",
    "\n",
    "\n",
    "# Important: Run on all sessions now to prepare for the rest of the notebook.\n",
    "populate_containers(sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5655b6",
   "metadata": {},
   "source": [
    "## Step 3: Synchronizing Timestamps\n",
    "\n",
    "Now that our data is loaded, we face the next challenge: the clocks from the photometry camera and the behavioral computer were not started at the exact same time.\n",
    "\n",
    "The `sync_session` function solves this by finding a common reference point in the data—the \"Set Blank Images\" event—and creating new, perfectly aligned timestamp columns.\n",
    "\n",
    "The cell below will show this process in action. You'll see it adds new columns like `sec_from_trial_start` to our data tables, making them ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cb4bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. Columns Before Syncing\n",
      "\n",
      "Photometry 'phot_470': ['LedState', 'FrameCounter', 'signal_0', 'signal_1', 'SystemTimestamp']\n",
      "Behavioral 'raw':      ['Evnt_ID', 'Arg2_Value', 'Arg3_Name', 'Num_Args', 'Item_Name', 'Evnt_Time', 'Arg1_Value', 'Evnt_Name', 'Alias_Name', 'Group_ID', 'Arg3_Value', 'Arg4_Name', 'Arg4_Value', 'Arg5_Value', 'Arg1_Name', 'Arg2_Name', 'Arg5_Name']\n",
      "\n",
      "## 2. Columns After Syncing\n",
      "\n",
      "Photometry 'phot_470': ['sec_from_zero', 'LedState', 'FrameCounter', 'signal_0', 'signal_1', 'SystemTimestamp', 'sec_from_trial_start']\n",
      "Behavioral 'raw':      ['Evnt_ID', 'Arg3_Name', 'Evnt_Time', 'Arg1_Value', 'Group_ID', 'Arg2_Name', 'Arg5_Name', 'Item_Name', 'Evnt_Name', 'Arg3_Value', 'sec_from_trial_start', 'Arg5_Value', 'sec_from_zero', 'Arg2_Value', 'Num_Args', 'Arg4_Value', 'Alias_Name', 'Arg1_Name', 'Arg4_Name']\n",
      "\n",
      "## 3. The Delta (Our New Synced Columns) ✅\n",
      "\n",
      "New columns in 'phot_470': ['sec_from_zero', 'sec_from_trial_start']\n",
      "New columns in 'raw':      ['sec_from_zero', 'sec_from_trial_start']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use a single session for the demonstration\n",
    "s0_for_sync_demo = sessions[0]\n",
    "\n",
    "# 1. Populate containers to load the data and capture the \"before\" state\n",
    "populate_containers([s0_for_sync_demo])\n",
    "cols_phot_before = set(s0_for_sync_demo.dfs.data['phot_470'].columns)\n",
    "cols_raw_before = set(s0_for_sync_demo.dfs.data['raw'].columns)\n",
    "\n",
    "print(\"## 1. Columns Before Syncing\\n\")\n",
    "print(f\"Photometry 'phot_470': {list(cols_phot_before)}\")\n",
    "print(f\"Behavioral 'raw':      {list(cols_raw_before)}\")\n",
    "\n",
    "# ---\n",
    "# 2. Run the synchronization function\n",
    "sync_session(s0_for_sync_demo)\n",
    "# ---\n",
    "\n",
    "# 3. Capture the \"after\" state\n",
    "cols_phot_after = set(s0_for_sync_demo.dfs.data['phot_470'].columns)\n",
    "cols_raw_after = set(s0_for_sync_demo.dfs.data['raw'].columns)\n",
    "\n",
    "print(\"\\n## 2. Columns After Syncing\\n\")\n",
    "print(f\"Photometry 'phot_470': {list(cols_phot_after)}\")\n",
    "print(f\"Behavioral 'raw':      {list(cols_raw_after)}\")\n",
    "\n",
    "# 4. Calculate and show the delta\n",
    "delta_phot = cols_phot_after - cols_phot_before\n",
    "delta_raw = cols_raw_after - cols_raw_before\n",
    "\n",
    "print(\"\\n## 3. The Delta (Our New Synced Columns) ✅\\n\")\n",
    "print(f\"New columns in 'phot_470': {list(delta_phot)}\")\n",
    "print(f\"New columns in 'raw':      {list(delta_raw)}\")\n",
    "\n",
    "\n",
    "# Important: Run on all sessions now to prepare for the rest of the notebook\n",
    "populate_containers(sessions)\n",
    "for session in sessions:\n",
    "    sync_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc490d3c",
   "metadata": {},
   "source": [
    "## Step 4: Creating an Index of Event Occurrences\n",
    "\n",
    "While our data is loaded and synced, we still need an efficient way to find every instance of a specific behavior.\n",
    "\n",
    "The `create_event_idxs_container_for_sessions` function builds a dictionary that points to the exact **row number** for each event of interest in our raw data file.\n",
    "\n",
    "1.  **Define a Mapping**: The `actions_attr_dict` and `reward_attr_dict` serve as a map, telling the function which raw event names (like `\"Correct Rejection\"`) should be categorized under a simpler key (like `'cor_reject'`).\n",
    "\n",
    "2.  **Collect Row Indices**: The function then scans the event log and creates a list of every row index that corresponds to a given key. For example, it will create a list containing the row numbers for every single `'hit'`.\n",
    "\n",
    "3.  **Store the Index Lists**: These lists are stored in a new container on the session, `event_idxs_container`. This gives us a direct pointer to every occurrence of any behavior we want to analyze. The function also creates special indices, like finding the event that occurred immediately before or after a `'dispimg'` event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a63f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_attr_dict = {\"Hit\": \"hit\",\n",
    "                    \"Mistake\": \"mistake\", \n",
    "                    \"Missed Hit\": \"miss\",                    \n",
    "                    \"Correction Trial Correct Rejection\": \"cor_reject\", \n",
    "                    \"Correct Rejection\": \"cor_reject\"}\n",
    "\n",
    "reward_attr_dict = {\"Reward Collected Start ITI\": \"reward_collect\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea0900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_event_idxs_container_for_sessions(sessions, actions_attr_dict, reward_attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326f0b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iti_touch [13, 589, 618, 655, 1737, 1745, 1753, 1938, 1947, 2466, 2521, 2654, 2686, 3864, 4524, 4533, 4543, 4783, 4861, 5428, 5436, 5444, 5453, 5461, 5704, 6024, 6032, 6543, 6551, 6900, 7403, 7670, 7853, 8292, 8300, 8380, 8636, 8644, 8652, 8660, 8690]\n",
      "dispimg [97, 121, 145, 168, 190, 230, 255, 283, 307, 331, 369, 391, 414, 439, 462, 496, 519, 541, 565, 594, 627, 662, 684, 706, 744, 767, 790, 812, 834, 856, 878, 900, 922, 944, 966, 988, 1010, 1032, 1054, 1076, 1098, 1120, 1142, 1164, 1186, 1208, 1232, 1256, 1281, 1304, 1330, 1352, 1374, 1396, 1418, 1440, 1462, 1486, 1508, 1530, 1552, 1574, 1596, 1618, 1640, 1663, 1688, 1712, 1760, 1782, 1804, 1826, 1856, 1891, 1913, 1954, 1976, 1998, 2020, 2042, 2064, 2086, 2108, 2131, 2153, 2176, 2198, 2238, 2266, 2288, 2310, 2335, 2359, 2385, 2413, 2440, 2471, 2493, 2527, 2549, 2574, 2597, 2628, 2662, 2692, 2717, 2739, 2761, 2783, 2805, 2827, 2851, 2873, 2913, 2958, 2980, 3009, 3032, 3055, 3077, 3099, 3121, 3143, 3165, 3187, 3209, 3232, 3254, 3276, 3298, 3320, 3342, 3364, 3386, 3408, 3430, 3453, 3476, 3498, 3537, 3562, 3585, 3608, 3639, 3661, 3685, 3707, 3729, 3751, 3773, 3795, 3817, 3839, 3869, 3891, 3913, 3935, 3957, 3980, 4002, 4024, 4046, 4068, 4090, 4112, 4155, 4180, 4202, 4224, 4248, 4270, 4292, 4314, 4336, 4358, 4380, 4402, 4424, 4446, 4469, 4498, 4549, 4573, 4602, 4624, 4646, 4668, 4690, 4712, 4735, 4758, 4791, 4813, 4837, 4867, 4891, 4915, 4939, 4965, 4987, 5009, 5031, 5053, 5078, 5100, 5122, 5144, 5166, 5190, 5217, 5240, 5262, 5285, 5318, 5345, 5381, 5403, 5467, 5493, 5515, 5537, 5559, 5581, 5604, 5626, 5648, 5670, 5709, 5731, 5753, 5775, 5797, 5820, 5842, 5864, 5886, 5915, 5938, 5963, 5997, 6038, 6062, 6092, 6122, 6146, 6171, 6196, 6228, 6260, 6296, 6324, 6362, 6390, 6412, 6436, 6458, 6480, 6517, 6556, 6578, 6600, 6622, 6644, 6671, 6695, 6718, 6756, 6780, 6806, 6830, 6854, 6876, 6905, 6927, 6950, 6974, 6997, 7025, 7065, 7087, 7109, 7131, 7153, 7175, 7199, 7222, 7244, 7266, 7288, 7310, 7333, 7356, 7379, 7410, 7433, 7462, 7498, 7523, 7545, 7588, 7623, 7646, 7675, 7721, 7746, 7769, 7801, 7825, 7859, 7881, 7913, 7951, 7976, 7998, 8020, 8042, 8064, 8087, 8109, 8131, 8153, 8175, 8198, 8221, 8264, 8308, 8334, 8356, 8385, 8407, 8429, 8451, 8473, 8495, 8518, 8540, 8562, 8587, 8612, 8666, 8695, 8717, 8739, 8761, 8784]\n",
      "hit [197, 338, 469, 712, 1862, 2206, 2879, 2926, 3506, 4118, 5351, 6487, 7034, 7468, 7558, 7687, 7921, 8234]\n",
      "mistake [421, 1336, 2159, 2698, 3414, 3459, 4162, 4230, 4586, 5474, 5683, 7385, 7629, 8317]\n",
      "miss [109, 156, 575, 754, 866, 932, 976, 998, 1086, 1152, 1174, 1269, 1384, 1428, 1450, 1562, 1650, 1770, 1843, 1986, 2119, 2141, 2298, 2345, 2398, 2451, 2672, 2771, 2815, 2861, 3153, 3175, 3264, 3286, 3308, 3396, 3619, 3673, 3695, 3805, 3923, 3968, 4034, 4100, 4324, 4390, 4412, 4434, 4560, 4678, 4745, 4878, 4975, 4997, 5088, 5154, 5176, 5203, 5525, 5569, 5636, 5807, 5830, 5874, 5985, 6010, 6184, 6245, 6278, 6377, 6422, 6654, 6734, 6766, 6864, 6962, 6984, 7075, 7232, 7276, 7609, 7812, 7837, 8052, 8097, 8208, 8417, 8483, 8528, 8572, 8676, 8727]\n",
      "cor_reject [133, 178, 241, 269, 294, 317, 379, 402, 450, 507, 529, 553, 604, 637, 672, 694, 778, 800, 822, 844, 888, 910, 954, 1020, 1042, 1064, 1108, 1130, 1196, 1220, 1242, 1292, 1315, 1362, 1406, 1473, 1496, 1518, 1540, 1584, 1606, 1628, 1673, 1700, 1722, 1792, 1814, 1901, 1923, 1964, 2008, 2030, 2052, 2074, 2096, 2186, 2253, 2276, 2323, 2372, 2426, 2481, 2505, 2537, 2561, 2585, 2614, 2640, 2727, 2749, 2793, 2837, 2968, 2991, 3020, 3043, 3065, 3087, 3109, 3131, 3197, 3219, 3242, 3330, 3352, 3374, 3441, 3486, 3547, 3573, 3596, 3649, 3717, 3739, 3761, 3783, 3827, 3851, 3879, 3901, 3945, 3990, 4012, 4056, 4078, 4190, 4212, 4258, 4280, 4302, 4346, 4368, 4456, 4486, 4509, 4612, 4634, 4656, 4700, 4723, 4768, 4801, 4824, 4847, 4901, 4925, 4949, 5019, 5041, 5066, 5110, 5132, 5227, 5250, 5272, 5305, 5331, 5391, 5413, 5503, 5547, 5591, 5614, 5658, 5719, 5741, 5763, 5785, 5852, 5901, 5926, 5948, 6048, 6079, 6108, 6133, 6156, 6210, 6312, 6334, 6400, 6446, 6468, 6528, 6566, 6588, 6610, 6632, 6683, 6705, 6794, 6816, 6842, 6886, 6915, 6938, 7010, 7097, 7119, 7141, 7163, 7185, 7210, 7254, 7298, 7321, 7344, 7366, 7420, 7450, 7508, 7533, 7656, 7732, 7757, 7788, 7869, 7891, 7964, 7986, 8008, 8030, 8075, 8119, 8141, 8163, 8185, 8277, 8344, 8366, 8395, 8439, 8461, 8506, 8550, 8599, 8622, 8705, 8749, 8772]\n",
      "reward_collect [209, 350, 480, 725, 1874, 2219, 2894, 2939, 3520, 4133, 5364, 6498, 7048, 7480, 7570, 7700, 7934, 8246]\n"
     ]
    }
   ],
   "source": [
    "for k, v in sessions[0].event_idxs_container.data.items():\n",
    "    if k.startswith('before') or k.startswith('after'):\n",
    "        continue\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b2a33",
   "metadata": {},
   "source": [
    "## Step 5: Applying the Signal Processing Pipeline\n",
    "\n",
    "This step applies our chosen signal processing pipeline to the raw fluorescence data.\n",
    "\n",
    "1.  **Define Processing Parameters**: The `PLOTTING_CONFIG` dictionary sets the rules for the analysis. Crucially, it defines the `fit_window_start` and `fit_window_end` which specify the exact time window used to calculate the baseline for dF/F calculations.\n",
    "\n",
    "2.  **Apply the Pipeline**: The `PlottingSetup` class uses these parameters to process each signal. In this notebook, we use the `calculate_dff_and_zscore` method by default, which performs an isosbestic-based motion correction and then computes the z-scored dF/F.\n",
    "\n",
    "3.  **Modular Design**: The code is structured so that different processing methods can be easily swapped. The main `apply_phot_iso_calculation` function can be passed any compatible function, like `calculate_dff_exp2_iso`, allowing for flexible analysis without changing the core workflow.\n",
    "\n",
    "The final, processed signal is saved as a new `_dff` column in the photometry data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f530391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. State Before Signal Processing\n",
      "\n",
      "Columns in 'phot_470': ['sec_from_zero', 'LedState', 'FrameCounter', 'signal_0', 'signal_1', 'SystemTimestamp', 'sec_from_trial_start']\n",
      "Session has 'trial_start_idx' attribute: False\n",
      "\n",
      "## 2. State After Signal Processing\n",
      "\n",
      "Columns in 'phot_470': ['sec_from_zero', 'LedState', 'FrameCounter', 'signal_0', 'signal_0_dff', 'signal_1', 'SystemTimestamp', 'sec_from_trial_start', 'signal_1_dff']\n",
      "Session has 'trial_start_idx' attribute: True\n",
      "Value of 'trial_start_idx': 40392\n",
      "Value of 'fit_start' index: 21192\n",
      "\n",
      "## 3. The Delta (What We Added) ✅\n",
      "\n",
      "The function added new attributes to the session object to define key time windows.\n",
      "It also added the final processed dF/F columns to the data tables: ['signal_0_dff', 'signal_1_dff']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use a single session for the demonstration\n",
    "s0_for_dff_demo = sessions[0]\n",
    "\n",
    "# ---\n",
    "# 1. The \"Before\" State\n",
    "# ---\n",
    "print(\"## 1. State Before Signal Processing\\n\")\n",
    "phot_470_cols_before = set(s0_for_dff_demo.dfs.data['phot_470'].columns)\n",
    "print(f\"Columns in 'phot_470': {list(phot_470_cols_before)}\")\n",
    "print(f\"Session has 'trial_start_idx' attribute: {hasattr(s0_for_dff_demo, 'trial_start_idx')}\")\n",
    "\n",
    "# ---\n",
    "# 2. Run the PlottingSetup function\n",
    "# ---\n",
    "PlottingSetup(**PLOTTING_CONFIG['cpt']).apply_plotting_setup_to_sessions([s0_for_dff_demo])\n",
    "\n",
    "# ---\n",
    "# 3. The \"After\" State\n",
    "# ---\n",
    "print(\"\\n## 2. State After Signal Processing\\n\")\n",
    "phot_470_cols_after = set(s0_for_dff_demo.dfs.data['phot_470'].columns)\n",
    "print(f\"Columns in 'phot_470': {list(phot_470_cols_after)}\")\n",
    "print(f\"Session has 'trial_start_idx' attribute: {hasattr(s0_for_dff_demo, 'trial_start_idx')}\")\n",
    "print(f\"Value of 'trial_start_idx': {s0_for_dff_demo.trial_start_idx}\")\n",
    "print(f\"Value of 'fit_start' index: {s0_for_dff_demo.fit_start}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# 4. The Delta\n",
    "# ---\n",
    "delta_cols = phot_470_cols_after - phot_470_cols_before\n",
    "print(\"\\n## 3. The Delta (What We Added) ✅\\n\")\n",
    "print(\"The function added new attributes to the session object to define key time windows.\")\n",
    "print(f\"It also added the final processed dF/F columns to the data tables: {list(delta_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0bf52",
   "metadata": {},
   "source": [
    "## Step 6: Creating Event-Triggered Signal Matrices\n",
    "\n",
    "This is the final step in our data preparation pipeline. We now have our processed neural signals (dF/F) and a complete index of when every behavioral event occurred (`event_idxs_container`). This function, `assign_sessions_signal_info`, brings them together to create data structures ready for analysis and plotting.\n",
    "\n",
    "Here’s how it works:\n",
    "1.  **Iterate Through Events**: The code goes through every event type we defined (e.g., 'hit', 'miss', 'reward_collect').\n",
    "2.  **Extract Signal Snippets**: For each individual occurrence of an event, it finds the corresponding time in the dF/F signal and cuts out a small window of data (a \"snippet\") from a few seconds before to a few seconds after the event.\n",
    "3.  **Stack into a Matrix**: All the snippets for a given event type are collected and stacked into a **`signal_matrix`** (a 2D NumPy array). Each row in this matrix represents the neural signal for a single trial of that event type.\n",
    "\n",
    "This final `signal_info` object contains these matrices, making downstream analysis—like calculating the average response to an event or plotting a heatmap of all trials—incredibly straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d246e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. State Before Creating Signal Matrices\n",
      "\n",
      "Session has 'signal_info' attribute: False\n",
      "\n",
      "## 2. State After Creating Signal Matrices\n",
      "\n",
      "Session has 'signal_info' attribute: True\n",
      "\n",
      "Example contents of 'signal_info':\n",
      "- Key: ('DLS', 'G', 'iti_touch'), Matrix Shape: (41, 400)\n",
      "- Key: ('DLS', 'G', 'dispimg'), Matrix Shape: (345, 400)\n",
      "- Key: ('DLS', 'G', 'hit'), Matrix Shape: (18, 400)\n",
      "\n",
      "## 3. The Delta (What We Added) ✅\n",
      "\n",
      "The function added the 'signal_info' attribute to the session.\n",
      "This dictionary contains the final event-triggered signal matrices, ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# Use a single session for the demonstration\n",
    "s0_for_matrix_demo = sessions[0]\n",
    "\n",
    "# ---\n",
    "# 1. The \"Before\" State\n",
    "# ---\n",
    "print(\"## 1. State Before Creating Signal Matrices\\n\")\n",
    "print(f\"Session has 'signal_info' attribute: {hasattr(s0_for_matrix_demo, 'signal_info')}\")\n",
    "\n",
    "# ---\n",
    "# 2. Run the assign_sessions_signal_info function\n",
    "# ---\n",
    "assign_sessions_signal_info([s0_for_matrix_demo])\n",
    "\n",
    "# ---\n",
    "# 3. The \"After\" State\n",
    "# ---\n",
    "print(\"\\n## 2. State After Creating Signal Matrices\\n\")\n",
    "print(f\"Session has 'signal_info' attribute: {hasattr(s0_for_matrix_demo, 'signal_info')}\")\n",
    "\n",
    "# Show a few examples of what's inside the new 'signal_info' dictionary\n",
    "print(\"\\nExample contents of 'signal_info':\")\n",
    "count = 0\n",
    "for key, value in s0_for_matrix_demo.signal_info.items():\n",
    "    if 'before' not in key[2] and 'after' not in key[2]: # Filter for clarity\n",
    "        matrix_shape = value['signal_matrix'].shape\n",
    "        print(f\"- Key: {key}, Matrix Shape: {matrix_shape}\")\n",
    "        count += 1\n",
    "        if count >= 3:\n",
    "            break\n",
    "\n",
    "# ---\n",
    "# 4. The Delta\n",
    "# ---\n",
    "print(\"\\n## 3. The Delta (What We Added) ✅\\n\")\n",
    "print(\"The function added the 'signal_info' attribute to the session.\")\n",
    "print(\"This dictionary contains the final event-triggered signal matrices, ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd20be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'signal_0_dff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/fiberphoto-demo/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'signal_0_dff'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43massign_sessions_signal_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msessions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/processing/signal_info_setup.py:186\u001b[0m, in \u001b[0;36massign_sessions_signal_info\u001b[0;34m(sessions)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mIterate sessions and attach the full signal_info dict.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m sessions:\n\u001b[0;32m--> 186\u001b[0m     session\u001b[38;5;241m.\u001b[39msignal_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_session_signal_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/processing/signal_info_setup.py:168\u001b[0m, in \u001b[0;36mget_session_signal_info\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    166\u001b[0m m \u001b[38;5;241m=\u001b[39m suffix_re\u001b[38;5;241m.\u001b[39mmatch(event_key)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# full key\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m info_full \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbr_region\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m signal_info[(br, color, event_key)] \u001b[38;5;241m=\u001b[39m info_full\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# base key if present\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/processing/signal_info_setup.py:39\u001b[0m, in \u001b[0;36mEventSignalExtractor.extract\u001b[0;34m(self, event_type, brain_region)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event_idxs:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo event indices for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m matrix, ranges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_signal_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphot_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_time_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_time_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignal_col\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m metrics \u001b[38;5;241m=\u001b[39m calculate_signal_response_metrics_matrix(matrix, response_interval, fps)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m:     matrix,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal_idx_ranges\u001b[39m\u001b[38;5;124m\"\u001b[39m: ranges,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m:  metrics,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphot_pointer\u001b[39m\u001b[38;5;124m\"\u001b[39m:      phot_df[signal_col],\n\u001b[1;32m     53\u001b[0m }\n",
      "File \u001b[0;32m~/Desktop/GetherLabCode/FiberphotometryCode/fiberphotometry/notebooks/demos/../../../fiberphotometry/processing/signal_info_setup.py:132\u001b[0m, in \u001b[0;36mEventSignalExtractor._build_signal_matrix\u001b[0;34m(self, raw_event_idxs, phot_df, raw_times, phot_times, brain_region)\u001b[0m\n\u001b[1;32m    129\u001b[0m e \u001b[38;5;241m=\u001b[39m pidx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_end\n\u001b[1;32m    130\u001b[0m idx_ranges\u001b[38;5;241m.\u001b[39mappend((s, e))\n\u001b[0;32m--> 132\u001b[0m trace    \u001b[38;5;241m=\u001b[39m     \u001b[43mphot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbrain_region\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_dff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[s:e]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m    133\u001b[0m pre_mean \u001b[38;5;241m=\u001b[39m trace[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_start\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterval_start\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    134\u001b[0m matrix[i] \u001b[38;5;241m=\u001b[39m trace \u001b[38;5;241m-\u001b[39m pre_mean\n",
      "File \u001b[0;32m/opt/miniconda3/envs/fiberphoto-demo/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/fiberphoto-demo/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'signal_0_dff'"
     ]
    }
   ],
   "source": [
    "assign_sessions_signal_info(sessions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiberphoto-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
